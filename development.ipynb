{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import PhiAgent\n",
    "from config.aiservice import run_agent\n",
    "from config.prompt import PROMPT\n",
    "import datetime\n",
    "from agent.tools.web_tools import web_tools\n",
    "from langchain_core.messages import HumanMessage, AIMessageChunk, ToolMessage\n",
    "from utils.utils import format_output, format_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-08 23:39:40.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.aiservice\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mModel name: gpt-4o-mini\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "(agent, config, memory) = run_agent(\n",
    "    model_name=model_name,\n",
    "    tools=web_tools,\n",
    "    system_prompt=PROMPT.format(date=str(datetime.datetime.now().date())),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_kwargs': '{\"input\":\"newest model from OpenAI\"}', 'tool_name': 'process_search_results', 'type': 'thought_update', 'id': 'id123'}\n",
      "{'tool_kwargs': '{\"url\": \"https://www.pymnts.com/artificial-intelligence-2/2025/sam-altman-openais-new-model-passes-agi-threshold/\"}', 'tool_name': 'async_get_page_content', 'type': 'thought_update', 'id': 'id123'}\n",
      "The newest model from OpenAI, as discussed by CEO Sam Altman, is set to be introduced on January 10, 2025. This model reportedly passes the ARC-AGI challenge, which assesses a model's ability to rely more on reasoning than on training data to achieve artificial general intelligence (AGI). Altman mentioned that their system scored 87.5% on this challenge, surpassing the required 85% threshold.\n",
      "\n",
      "In a recent interview, Altman emphasized that the term \"AGI\" has become somewhat ambiguous and discussed the importance of having specific benchmarks to measure progress in AI development. He also hinted at promising research and better models to come in the future.\n",
      "\n",
      "For more details, you can read the full article [here](https://www.pymnts.com/artificial-intelligence-2/2025/sam-altman-openais-new-model-passes-agi-threshold/). \n",
      "\n",
      "Additionally, you can find ongoing discussions and updates about OpenAI's models on platforms like [Reddit](https://www.reddit.com/r/OpenAI/new/)."
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [HumanMessage(content=\"newest model from openai?\")]}\n",
    "resp = agent.astream(input=input, config=config, stream_mode=[\"messages\", \"updates\"])\n",
    "response = \"\"\n",
    "async for event, msg in resp:\n",
    "                if event == \"messages\" and isinstance(msg[0], AIMessageChunk):\n",
    "                    msg_chunk = format_output(msg[0], model_name=model_name)\n",
    "                    response += msg_chunk\n",
    "                    print(msg_chunk, end=\"\", flush=True)\n",
    "\n",
    "                elif event == \"updates\":\n",
    "                    # messages_list = msg[\"messages\"]\n",
    "                    # newest_message = messages_list\n",
    "         \n",
    "                    if \"agent\" in msg.keys() and not msg[\"agent\"][\"messages\"][0].content:\n",
    "                        ai_message_update_value = msg[\"agent\"][\"messages\"][0]\n",
    "                        log_data = format_tool_call(\n",
    "                            ai_message_update_value,\n",
    "                            model_name,\n",
    "                           \"id123\",\n",
    "                        )\n",
    "                        print(log_data)\n",
    "                    # if isinstance(newest_message, ToolMessage):\n",
    "                    #     ai_message_update_value = messages_list[-2]\n",
    "                    #     print(ai_message_update_value)\n",
    "                    #     log_data = format_tool_call(\n",
    "                    #         ai_message_update_value,\n",
    "                    #         model_name,\n",
    "                    #         newest_message.tool_call_id,\n",
    "                    #     )\n",
    "                        # print(log_data)\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_hVwPK1eT2YRJLzUIGSmBVZuU', 'function': {'arguments': '{\"input\":\"newest model from OpenAI\"}', 'name': 'process_search_results'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b'}, id='run-7a9117e7-3a3e-4c70-b249-55a75670e6ec', tool_calls=[{'name': 'process_search_results', 'args': {'input': 'newest model from OpenAI'}, 'id': 'call_hVwPK1eT2YRJLzUIGSmBVZuU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 178, 'output_tokens': 20, 'total_tokens': 198, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "from pprint import  pprint\n",
    "pprint(msg[\"agent\"][\"messages\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
